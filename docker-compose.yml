version: "3.8"

services:
  redis:
    image: redis:7.0.11-alpine

  django:
    container_name: django
    build:
      context: ./dcelery
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - ./dcelery:/usr/src/app/
    ports:
      - 8001:8000
    environment:
      - DEBUG=1
      - SECRET_KEY=django-insecure-td=+9m#af*sdi!@q2+d*^%-dw89r$m8skkp9^6prjw$!-qnf&y
      - ALLOWED_HOSTS=localhost,127.0.0.1 
    depends_on:
      - redis

  celery:
    container_name: celery1
    build:
      context: ./dcelery
    command: celery --app=dcelery worker -l INFO  
    # command: celery --app=dcelery worker -l INFO --concurrency=1
    # command: celery --app=dcelery worker -l INFO -Q celery_1,celery_2,celery_3,
    # command: celery -A dcelery worker --loglevel=info
    # command: celery -A dcelery worker --uid=nobody --loglevel=INFO
    volumes:
      - ./dcelery:/usr/src/app/
    # ports:
    #   - 8001:8000
    environment:
      - DEBUG=1
      - SECRET_KEY=django-insecure-td=+9m#af*sdi!@q2+d*^%-dw89r$m8skkp9^6prjw$!-qnf&y
      - ALLOWED_HOSTS=localhost,127.0.0.1 
      - CELERY_BROKER=redis://redis:6379/0      
      - CELERY_RESULT_BACKEND=redis://redis:6379/0 
    depends_on:
      - redis
      - django


  # celery2:
  #   container_name: celery2
  #   build:
  #     context: ./celeryworker
  #     dockerfile: Dockerfile
  #   command: celery -A celerytask worker --loglevel=INFO -Q queue2
  #   volumes:
  #     - ./celeryworker:/usr/src/app/
  #   depends_on:
  #     - redis
  #     - django
